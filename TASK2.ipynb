{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9ce73d-ad22-41c7-a570-ed62d5864d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to 'compound_wallet_transactions.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Load wallet addresses from Excel\n",
    "wallets_df = pd.read_excel(r\"C:\\Users\\Anjani Kumar\\Downloads\\Wallet id.xlsx\")  # Make sure this file exists in the same folder\n",
    "wallets = wallets_df['wallet_id'].str.lower().dropna().unique().tolist()\n",
    "\n",
    "API_KEY = \"API KEY HERE\"  # Replace with your Covalent API key\n",
    "\n",
    "# Example Compound V2 token contracts\n",
    "compound_contracts = [\n",
    "    \"0x5d3a536e4d6dbd6114cc1ead35777bab948e3643\",  # cDAI\n",
    "    \"0x39aa39c021dfbae8fac545936693ac917d5e7563\",  # cUSDC\n",
    "    \"0x4ddc2d193948926d02f9b1fe9e1daa0718270ed5\",  # cETH\n",
    "    \"0xccf4429db6322d5c611ee964527d42e5d685dd6a\",  # cWBTC\n",
    "]\n",
    "\n",
    "def fetch_transactions(wallet, contract=None):\n",
    "    base_url = f\"https://api.covalenthq.com/v1/1/address/{wallet}/transfers_v2/\"\n",
    "    params = {\n",
    "        \"key\": API_KEY,\n",
    "        \"contract-address\": contract,\n",
    "        \"page-size\": 1000\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return pd.json_normalize(data['data']['items'])\n",
    "    else:\n",
    "        print(f\"Failed for {wallet} | Status: {response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Fetch all transactions\n",
    "all_txns = []\n",
    "\n",
    "for wallet in wallets:\n",
    "    for contract in compound_contracts:\n",
    "        df = fetch_transactions(wallet, contract)\n",
    "        if not df.empty:\n",
    "            df['wallet'] = wallet\n",
    "            all_txns.append(df)\n",
    "        time.sleep(1.2)\n",
    "\n",
    "# Save to CSV\n",
    "if all_txns:\n",
    "    final_df = pd.concat(all_txns, ignore_index=True)\n",
    "    final_df.to_csv(\"compound_wallet_transactions.csv\", index=False)\n",
    "    print(\"✅ Saved to 'compound_wallet_transactions.csv'\")\n",
    "else:\n",
    "    print(\"❌ No data retrieved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e5eee47-ac23-4c56-a588-ff580bab2045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Features saved to 'wallet_features.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load transaction data\n",
    "df = pd.read_csv(\"compound_wallet_transactions.csv\")\n",
    "\n",
    "# Convert timestamp to datetime if available\n",
    "if 'block_signed_at' in df.columns:\n",
    "    df['timestamp'] = pd.to_datetime(df['block_signed_at'])\n",
    "\n",
    "# Normalize token transfer values (convert raw values using token decimals)\n",
    "df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "df = df.dropna(subset=['value'])\n",
    "\n",
    "# Group-level features per wallet\n",
    "features = df.groupby('wallet').agg({\n",
    "    'value': ['sum', 'mean', 'max', 'count'],\n",
    "    'tx_hash': 'nunique',\n",
    "    'timestamp': ['min', 'max'],\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten MultiIndex column names\n",
    "features.columns = ['_'.join(col).strip('_') for col in features.columns.values]\n",
    "\n",
    "# Rename for clarity\n",
    "features.rename(columns={\n",
    "    'wallet_': 'wallet',\n",
    "    'value_sum': 'total_value_transferred',\n",
    "    'value_mean': 'avg_tx_value',\n",
    "    'value_max': 'max_tx_value',\n",
    "    'value_count': 'tx_count',\n",
    "    'tx_hash_nunique': 'unique_txns',\n",
    "    'timestamp_min': 'first_tx_time',\n",
    "    'timestamp_max': 'last_tx_time',\n",
    "}, inplace=True)\n",
    "\n",
    "# Time-related features\n",
    "features['activity_span_days'] = (\n",
    "    pd.to_datetime(features['last_tx_time']) - pd.to_datetime(features['first_tx_time'])\n",
    ").dt.days + 1\n",
    "\n",
    "# Fill any missing or zero activity spans\n",
    "features['activity_span_days'] = features['activity_span_days'].replace(0, 1)\n",
    "\n",
    "# Normalize transactional intensity\n",
    "features['tx_per_day'] = features['tx_count'] / features['activity_span_days']\n",
    "\n",
    "# Drop time fields if not needed\n",
    "features.drop(['first_tx_time', 'last_tx_time'], axis=1, inplace=True)\n",
    "\n",
    "# Save feature set\n",
    "features.to_csv(\"wallet_features.csv\", index=False)\n",
    "print(\"✅ Features saved to 'wallet_features.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c417dbff-6a51-42a2-a34c-9c057cb1ca84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved risk scores to 'wallet_risk_scores.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Load wallet features\n",
    "df = pd.read_csv(\"wallet_features.csv\")\n",
    "\n",
    "# Keep wallet ID aside\n",
    "wallets = df['wallet']\n",
    "X = df.drop(columns=['wallet'])\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert scaled data back to DataFrame for clustering logic\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# KMeans for proxy labeling (unsupervised learning)\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "proxy_labels = kmeans.fit_predict(X_scaled_df)\n",
    "\n",
    "# Identify safer cluster using a meaningful column\n",
    "# Choose the best available column from your features\n",
    "possible_safe_features = ['avg_tx_value', 'tx_count', 'total_value_transferred', 'tx_per_day']\n",
    "available_columns = X_scaled_df.columns.tolist()\n",
    "\n",
    "# Pick the first matching safe feature\n",
    "for col in possible_safe_features:\n",
    "    if col in available_columns:\n",
    "        safe_column = col\n",
    "        break\n",
    "else:\n",
    "    # Default to first column if none of the known ones are found\n",
    "    safe_column = available_columns[0]\n",
    "\n",
    "# Group stats by cluster and find which is safer (higher value of the chosen feature)\n",
    "cluster_stats = X_scaled_df.groupby(proxy_labels).mean()\n",
    "safe_cluster = cluster_stats[safe_column].idxmax()\n",
    "\n",
    "# Assign binary label: 1 = safe, 0 = risky\n",
    "y = (proxy_labels == safe_cluster).astype(int)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_scaled, y)\n",
    "\n",
    "# Get probability of being safe\n",
    "probs = rf.predict_proba(X_scaled)[:, 1]\n",
    "\n",
    "# Scale to 0–1000 as final score\n",
    "credit_scores = (probs * 1000).astype(int)\n",
    "\n",
    "# Final result\n",
    "result_df = pd.DataFrame({\n",
    "    'wallet_id': wallets,\n",
    "    'score': credit_scores\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "result_df.to_csv(\"wallet_risk_scores.csv\", index=False)\n",
    "print(\"✅ Saved risk scores to 'wallet_risk_scores.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea505d-54dc-4232-a5ee-6f486e5a6352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a30aea-4470-4dfa-9cbd-eaf104284a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
